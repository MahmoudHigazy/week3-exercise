{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahmoudHigazy/week3-exercise/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "outputId": "f660e53a-fb5e-436f-83d2-bb1c4d60af01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "12befd58-3838-44aa-b0de-83d1ec55c043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-02 14:13:31--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  66.9MB/s    in 1.3s    \n",
            "\n",
            "2019-11-02 14:13:32 (66.9 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "13e2f0cb-bd6f-49bf-eb45-0e22252401da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "d133da62-4249-4526-9242-7c1be00a6b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 2,048 hidden units and ReLU activation\n",
        "x = layers.Dense(2048, activation='relu')(x)\n",
        "# Add a dropout rate of 0.4\n",
        "x = layers.Dropout(.4)(x)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.1\n",
        "x = layers.Dropout(.1)(x)                    \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.0001), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2048)         77072384    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 512)          1049088     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            513         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 87,097,249\n",
            "Trainable params: 78,121,985\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "f268a5df-d2c8-493a-d3da-f8fb9e83a7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-02 14:50:17--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "\r/tmp/horse-or-human   0%[                    ]       0  --.-KB/s               \r/tmp/horse-or-human  11%[=>                  ]  16.01M  37.7MB/s               \r/tmp/horse-or-human  44%[=======>            ]  64.01M  98.9MB/s               \r/tmp/horse-or-human  61%[===========>        ]  88.01M  91.5MB/s               \r/tmp/horse-or-human  73%[=============>      ] 104.51M  90.0MB/s               \r/tmp/horse-or-human  92%[=================>  ] 132.16M  97.1MB/s               \r/tmp/horse-or-human  96%[==================> ] 137.67M  88.2MB/s               \r/tmp/horse-or-human 100%[===================>] 142.65M  90.3MB/s    in 1.6s    \n",
            "\n",
            "2019-11-02 14:50:19 (90.3 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-11-02 14:50:21--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  22.4MB/s    in 0.5s    \n",
            "\n",
            "2019-11-02 14:50:22 (22.4 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "ad47471f-12ce-40ff-e857-ae3488fbaa68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "1dd2ac52-d2aa-4b9f-cb90-aacf85737298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                   rotation_range=.4,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=13,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150,150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150,150))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "81cb7cd2-de7d-4e4e-b256-520da103ffb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              steps_per_epoch=79,\n",
        "                              epochs=100,\n",
        "                              validation_steps=12,\n",
        "                              verbose=2,\n",
        "                              callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "79/79 - 20s - loss: 0.1991 - acc: 0.9221 - val_loss: 0.0053 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.1265 - acc: 0.9601 - val_loss: 0.0199 - val_acc: 0.9917\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0435 - acc: 0.9844 - val_loss: 0.0177 - val_acc: 0.9958\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0396 - acc: 0.9864 - val_loss: 0.1043 - val_acc: 0.9750\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "79/79 - 15s - loss: 0.0524 - acc: 0.9834 - val_loss: 0.0724 - val_acc: 0.9917\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "79/79 - 15s - loss: 0.0783 - acc: 0.9786 - val_loss: 0.0344 - val_acc: 0.9958\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0521 - acc: 0.9883 - val_loss: 0.0539 - val_acc: 0.9958\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "79/79 - 15s - loss: 0.0402 - acc: 0.9873 - val_loss: 0.0648 - val_acc: 0.9958\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0385 - acc: 0.9903 - val_loss: 0.1693 - val_acc: 0.9792\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0160 - acc: 0.9961 - val_loss: 0.1721 - val_acc: 0.9750\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0309 - acc: 0.9942 - val_loss: 0.1177 - val_acc: 0.9875\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0332 - acc: 0.9932 - val_loss: 0.3476 - val_acc: 0.9583\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0274 - acc: 0.9932 - val_loss: 0.2150 - val_acc: 0.9833\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0509 - acc: 0.9903 - val_loss: 0.1453 - val_acc: 0.9833\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0560 - acc: 0.9854 - val_loss: 0.0434 - val_acc: 0.9958\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0485 - acc: 0.9912 - val_loss: 0.8867 - val_acc: 0.9458\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0128 - acc: 0.9971 - val_loss: 0.4142 - val_acc: 0.9667\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0508 - acc: 0.9912 - val_loss: 0.0494 - val_acc: 0.9958\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0256 - acc: 0.9932 - val_loss: 0.1532 - val_acc: 0.9833\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0263 - acc: 0.9971 - val_loss: 0.5760 - val_acc: 0.9583\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0547 - acc: 0.9912 - val_loss: 0.2335 - val_acc: 0.9792\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "79/79 - 15s - loss: 0.0212 - acc: 0.9951 - val_loss: 0.2081 - val_acc: 0.9833\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0372 - acc: 0.9903 - val_loss: 0.4845 - val_acc: 0.9667\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0129 - acc: 0.9981 - val_loss: 0.2246 - val_acc: 0.9833\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0589 - acc: 0.9912 - val_loss: 0.2391 - val_acc: 0.9833\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0789 - acc: 0.9873 - val_loss: 0.6130 - val_acc: 0.9583\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.3934 - val_acc: 0.9750\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0377 - acc: 0.9932 - val_loss: 0.2351 - val_acc: 0.9792\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0109 - acc: 0.9971 - val_loss: 0.4292 - val_acc: 0.9708\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0420 - acc: 0.9912 - val_loss: 0.3598 - val_acc: 0.9708\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0229 - acc: 0.9951 - val_loss: 0.9755 - val_acc: 0.9542\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0189 - acc: 0.9971 - val_loss: 0.3559 - val_acc: 0.9708\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0328 - acc: 0.9961 - val_loss: 0.3441 - val_acc: 0.9708\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0148 - acc: 0.9951 - val_loss: 0.4363 - val_acc: 0.9708\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0377 - acc: 0.9951 - val_loss: 0.3833 - val_acc: 0.9792\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "79/79 - 14s - loss: 0.0452 - acc: 0.9922 - val_loss: 0.2890 - val_acc: 0.9833\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "79/79 - 14s - loss: 0.0045 - acc: 0.9990 - val_loss: 0.1532 - val_acc: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "b66ca5b3-28d2-4926-cec9-65cede8d3819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scK5O_RGlHIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}